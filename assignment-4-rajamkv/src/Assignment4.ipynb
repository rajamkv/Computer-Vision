{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report ,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    classes = os.listdir(path+\"/train\")[:-1]\n",
    "    train = []\n",
    "    test = []\n",
    "    test_names = []\n",
    "    for label in classes:\n",
    "        train.append([])\n",
    "        for img_name in os.listdir(path + \"/train/\" + label):\n",
    "            im = cv2.imread(path + \"/train/\" + label + \"/\" + img_name,0)\n",
    "            if im is not None:\n",
    "                im = cv2.resize(im, (150, 150))\n",
    "                train[classes.index(label)].append(im)\n",
    "        test.append([])\n",
    "        test_names.append([])\n",
    "        test_img_path = path + \"/test/\" + label\n",
    "        for img_name in os.listdir(test_img_path):\n",
    "            img = cv2.imread(test_img_path + \"/\" + img_name,0)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (150, 150))\n",
    "                test[classes.index(label)].append(img)\n",
    "                test_names[classes.index(label)].append(img_name)\n",
    "    return classes,train,test,test_names\n",
    "# classes,train_imgs,test_imgs,test_names = load_data(\"../dataset/SUN_data/SUN_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sftfeat(imgs):\n",
    "    sift_vectors = []\n",
    "    descriptor_list = []\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    for i in range(len(imgs)):\n",
    "        features = []\n",
    "        for img in imgs[i]:\n",
    "            kp, des = sift.detectAndCompute(img,None)           \n",
    "            descriptor_list.extend(des)\n",
    "            features.append(des)\n",
    "        sift_vectors.append(features)\n",
    "    return [descriptor_list, sift_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findex(image, center):\n",
    "    c_dist = distance.euclidean(image,center[0])\n",
    "    ret = 0\n",
    "    for i in range(len(center[1:])):\n",
    "        d = distance.euclidean(image,center[i])\n",
    "        if(d<c_dist):\n",
    "            c_dist=d\n",
    "            ret = i+1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iclass(bovw, centers,norm_flag):\n",
    "    feature = []\n",
    "    for i in range(len(bovw)):\n",
    "        category = []\n",
    "        for img in bovw[i]:\n",
    "            hist = np.zeros(len(centers))\n",
    "            for j in range(len(img)):\n",
    "                index = findex(img[j], centers)\n",
    "                hist[index] += 1\n",
    "            if(norm_flag==1):\n",
    "                hist = hist/np.sum(hist)\n",
    "            category.append(hist)\n",
    "        feature.append(category)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganise_SVM(bovw_train,bovw_test,classes,test_names):\n",
    "    train_labels = []\n",
    "    X_train = []\n",
    "    X_test=  []\n",
    "    X_test_names=  []\n",
    "    test_labels = []\n",
    "    for i in range(len(bovw_train)):\n",
    "        for j in range(len(bovw_train[i])):\n",
    "            X_train.append(bovw_train[i][j])\n",
    "            train_labels.append(classes[i])\n",
    "        for j in range(len(bovw_test[i])):\n",
    "            X_test.append(bovw_test[i][j])\n",
    "            X_test_names.append(test_names[i][j])\n",
    "            test_labels.append(classes[i])\n",
    "    return X_train,train_labels,X_test,test_labels,X_test_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_fit(X_train,train_labels,X_test,test_labels):\n",
    "    model = OneVsRestClassifier(SVC(kernel='linear',C=0.03))\n",
    "    model.fit(X_train, train_labels)\n",
    "    prediction = model.predict(X_test)\n",
    "    print(f\"Test Set Accuracy : {accuracy_score(test_labels, prediction) * 100} %\\n\")\n",
    "    print(f\"Classification Report : \\n{classification_report(test_labels, prediction)}\")\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confs_matrix(classes,prediction,test_labels):\n",
    "    conf_matrix = []\n",
    "    conf_names = []\n",
    "    for i in range(len(classes)):\n",
    "        conf_matrix.append([0 for j in range(len(classes))])\n",
    "        conf_names.append([[] for j in range(len(classes))])\n",
    "    for i in range(len(prediction)):\n",
    "        conf_matrix[classes.index(prediction[i])][classes.index(test_labels[i])]+=1\n",
    "        conf_names[classes.index(prediction[i])][classes.index(test_labels[i])].append(X_test_names[i])\n",
    "    return conf_matrix,conf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes,train_imgs,test_imgs,test_names = load_data(\"../dataset/SUN_data/SUN_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sifts = sftfeat(train_imgs) \n",
    "descriptor_list = sifts[0] \n",
    "all_bovw_feature = sifts[1] \n",
    "test_bovw_feature = sftfeat(test_imgs)[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "We kmeans = MiniBatchKMeans(n_clusters = 8, n_init = 10)\n",
    "kmeans.fit(descriptor_list)\n",
    "visual_words = kmeans.cluster_centers_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bovw_train = iclass(all_bovw_feature, visual_words,0) \n",
    "bovw_test = iclass(test_bovw_feature, visual_words,0) \n",
    "bovw_train_norm = iclass(all_bovw_feature, visual_words,1) \n",
    "bovw_test_norm = iclass(test_bovw_feature, visual_words,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,train_labels,X_test,test_labels,X_test_names=reorganise_SVM(bovw_train,bovw_test,classes,test_names)\n",
    "X_train_norm,train_labels_norm,X_test_norm,test_labels_norm,X_test_names_norm=reorganise_SVM(bovw_train_norm,bovw_test_norm,classes,test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification without Normalisation\n",
      "----------------------------------------\n",
      "Test Set Accuracy : 35.625 %\n",
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    aquarium       0.33      0.20      0.25        20\n",
      "      desert       0.52      0.80      0.63        20\n",
      "     highway       0.33      0.05      0.09        20\n",
      "     kitchen       0.33      0.15      0.21        20\n",
      "  laundromat       0.31      0.45      0.37        20\n",
      "        park       0.31      0.55      0.40        20\n",
      "   waterfall       0.38      0.40      0.39        20\n",
      "    windmill       0.25      0.25      0.25        20\n",
      "\n",
      "    accuracy                           0.36       160\n",
      "   macro avg       0.35      0.36      0.32       160\n",
      "weighted avg       0.35      0.36      0.32       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification without Normalisation\\n----------------------------------------\")\n",
    "predictions = SVM_fit(X_train,train_labels,X_test,test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification with Normalisation\n",
      "----------------------------------------\n",
      "Test Set Accuracy : 22.5 %\n",
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    aquarium       0.00      0.00      0.00        20\n",
      "      desert       0.35      0.60      0.44        20\n",
      "     highway       0.33      0.05      0.09        20\n",
      "     kitchen       0.11      0.05      0.07        20\n",
      "  laundromat       0.20      0.60      0.30        20\n",
      "        park       0.24      0.25      0.24        20\n",
      "   waterfall       0.00      0.00      0.00        20\n",
      "    windmill       0.19      0.25      0.21        20\n",
      "\n",
      "    accuracy                           0.23       160\n",
      "   macro avg       0.18      0.23      0.17       160\n",
      "weighted avg       0.18      0.23      0.17       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification with Normalisation\\n----------------------------------------\")\n",
    "predictions_norm = SVM_fit(X_train_norm,train_labels_norm,X_test_norm,test_labels_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix,conf_names = confs_matrix(classes,predictions,test_labels)\n",
    "conf_matrix_norm,conf_names_norm = confs_matrix(classes,predictions_norm,test_labels_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> highway\n",
      "1 -> waterfall\n",
      "2 -> park\n",
      "3 -> windmill\n",
      "4 -> aquarium\n",
      "5 -> kitchen\n",
      "6 -> desert\n",
      "7 -> laundromat\n",
      "\n",
      "\n",
      "Confusion Matrix without Normalisation\n",
      "\n",
      "   0   1   2  3  4  5   6  7\n",
      "0  1   0   0  0  1  0   0  1\n",
      "1  1   8   3  2  4  2   0  1\n",
      "2  2  10  11  4  5  2   0  1\n",
      "3  5   0   1  5  3  3   1  2\n",
      "4  2   2   0  2  4  0   1  1\n",
      "5  2   0   0  1  0  3   0  3\n",
      "6  6   0   1  3  2  1  16  2\n",
      "7  1   0   4  3  1  9   2  9\n",
      "\n",
      "Confusion Matrix without Normalisation\n",
      "\n",
      "    0  1  2  3   4   5   6   7\n",
      "0   1  0  0  1   0   0   1   0\n",
      "1   0  0  1  0   1   1   0   0\n",
      "2   2  3  5  5   3   1   1   1\n",
      "3   5  2  2  5   2   5   3   3\n",
      "4   0  2  0  1   0   0   0   0\n",
      "5   1  3  3  0   1   1   0   0\n",
      "6  10  1  1  3   3   0  12   4\n",
      "7   1  9  8  5  10  12   3  12\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(classes)):\n",
    "    print(i,\"->\",classes[i])\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix with Normalisation\\n\")\n",
    "print(DataFrame(conf_matrix))\n",
    "print(\"\\nConfusion Matrix without Normalisation\\n\")\n",
    "print(DataFrame(conf_matrix_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sun_bwbhvftrpsasgenv.jpg Image in highway class is corectly classified\n",
      "sun_avdirymfvklsislz.jpg Image in aquarium class is wrongly classified as highway\n"
     ]
    }
   ],
   "source": [
    "# print(os.getcwd())\n",
    "# os.chdir(\"../dataset/SUN_data/SUN_data/test/\")\n",
    "for i in range(len(conf_names)):\n",
    "    if(len(conf_names[i][i])>0):\n",
    "        print(conf_names[i][i][0] + \" Image in \"+classes[i]+\" class is corectly classified\")\n",
    "        break\n",
    "fl = 1\n",
    "for i in range(len(conf_names)):\n",
    "    for j in range(len(conf_names[i])):\n",
    "        if(i!=j and len(conf_names[i][j])>0):\n",
    "            print(conf_names[i][j][0] + \" Image in \"+classes[j]+\" class is wrongly classified as \"+classes[i])\n",
    "            fl = 0\n",
    "            break\n",
    "    if(fl==0):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bag of Visual Words is used to classify by defining words from images using Kmeans \n",
    "- The following are the parameters to play around\n",
    "    - no of clusters in k-Means\n",
    "    - c in svm\n",
    "- It was observed that the higher the k the better the result \n",
    "- Accuracy values are  around 20-30% for k=8 and around 45-55% at k=150\n",
    "- Normalisation doesn't guarentee increase in inaccuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
